{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranj10/Cat_Dogs_Classification/blob/main/Cat_Dogs_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yl46Zv-Yov3V",
      "metadata": {
        "id": "Yl46Zv-Yov3V"
      },
      "source": [
        "**Steps to approach this project:-**\n",
        "1. Understand the process and read each and every comment for better understanding.\n",
        "2. Follow along the comment, if having problem in understanding any step, ask the mentor, also google first to exercise the brain.\n",
        "3. We have given steps to deal with train and validation images, and test part is for your experimentation.\n",
        "4. Spend some days on this project and google each term you encounter so that it sinks into your brain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ytz2PHBXs9qM",
      "metadata": {
        "id": "Ytz2PHBXs9qM"
      },
      "source": [
        "**Save the dataset as it is in a folder of your drive. Then connect it with the code below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NPb7U0EI1fSr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPb7U0EI1fSr",
        "outputId": "d229b348-61a0-4f7d-fd91-d2c17292587b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Use it to mount your drive with colab so that you can use dataset and do other operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17cb311d",
      "metadata": {
        "id": "17cb311d"
      },
      "outputs": [],
      "source": [
        "# Importing necessary library os for directory and shutil to copy files from one directory to the other\n",
        "import os, shutil\n",
        "\n",
        "# copy the path of main data and define a variable named original_dataset_dir\n",
        "original_dataset_dir = \"/content/drive/MyDrive/cat_dog_small/main_data\"\n",
        "\n",
        "# now we will create another directory named cat_dog parallel to main data, where you will create train, validation and test directory to\n",
        "#  store equal amount of images of dog and cat by copying it from main data directory\n",
        "# first define the path which is parallel to main data path\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/cat_dog_small/cat_dog\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42d5c57",
      "metadata": {
        "id": "e42d5c57"
      },
      "outputs": [],
      "source": [
        "# Now use os.mkdir(pass base_dir here) to create the base_dir\n",
        "\n",
        "# code here\n",
        "os.mkdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d8d51aa",
      "metadata": {
        "id": "8d8d51aa"
      },
      "outputs": [],
      "source": [
        "# Now connect base_dir to train, validation and test directories using --> os.path.join(pass base dir here, directory name you want to create)\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "test_dir = os.path.join(base_dir, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4f3cf3",
      "metadata": {
        "id": "1f4f3cf3"
      },
      "outputs": [],
      "source": [
        "# Use os.mkdir and create train_dir, validation_dir, test_dir\n",
        "\n",
        "# code here\n",
        "os.mkdir(train_dir)\n",
        "os.mkdir(validation_dir)\n",
        "os.mkdir(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edfe2d2a",
      "metadata": {
        "id": "edfe2d2a"
      },
      "outputs": [],
      "source": [
        "# Now connect dog and cat directory in train, validation and test using os.path.join() as we did earlier in base_dir\n",
        "train_cats_dir = os.path.join(train_dir,\"cats\")\n",
        "train_dogs_dir = os.path.join(train_dir,\"dogs\")\n",
        "\n",
        "val_cats_dir = os.path.join(validation_dir,\"cats\")\n",
        "val_dogs_dir = os.path.join(validation_dir,\"dogs\")\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir,\"cats\")\n",
        "test_dogs_dir = os.path.join(test_dir,\"dogs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe6f9af7",
      "metadata": {
        "id": "fe6f9af7"
      },
      "outputs": [],
      "source": [
        "# Use os.mkdir to create train_dogs_dir and train_cats_dir\n",
        "\n",
        "# code here\n",
        "os.mkdir(train_dogs_dir)\n",
        "os.mkdir(train_cats_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IRhfxDVa_8ag",
      "metadata": {
        "id": "IRhfxDVa_8ag"
      },
      "outputs": [],
      "source": [
        "# Use os.mkdir to create val_dogs_dir and val_cats_dir\n",
        "\n",
        "# code here\n",
        "os.mkdir(val_dogs_dir)\n",
        "os.mkdir(val_cats_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3mP5ITXj_8dO",
      "metadata": {
        "id": "3mP5ITXj_8dO"
      },
      "outputs": [],
      "source": [
        "# Use os.mkdir to create test_dogs_dir and test_cats_dir\n",
        "\n",
        "# code here\n",
        "os.mkdir(test_dogs_dir)\n",
        "os.mkdir(test_cats_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tE6TcIBHywe9",
      "metadata": {
        "id": "tE6TcIBHywe9"
      },
      "source": [
        "**Now we want to copy files from original directory to the base_dir. We will copy 1000 dog and cat images to the dog and cat folder in train directory.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d24437c",
      "metadata": {
        "id": "9d24437c"
      },
      "outputs": [],
      "source": [
        "# making a list of image captions of cat using list comprehension(here we are copying first 1000 images of cat)\n",
        "cnames = [f\"cat.{i}.jpg\" for i in range(1000)]\n",
        "\n",
        "# loop over caption names in cnames and define a variable src by connecting original directory with the caption,\n",
        "# and then copy image from src to dest,  where dest variable is created by connecting train_cats_dir with the caption.\n",
        "for cname in cnames:\n",
        "    src = os.path.join(original_dataset_dir, cname)\n",
        "    dest = os.path.join(train_cats_dir, cname)\n",
        "    shutil.copyfile(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i1arG3rUAUaB",
      "metadata": {
        "id": "i1arG3rUAUaB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a2a3260f-2130-465a-93d0-64f5cbfbcaca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-00c49592eeb7>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_dataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_cats_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                             \u001b[0m_fastcopy_fcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_COPYFILE_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# follow previous procedure as it is, just change only range(1000) --> range(1000, 1500)\n",
        "# also this time we are copying files to val_cats_dir, so change dest location to val_cats_dir.\n",
        "\n",
        "cnames = [f\"cat.{i}.jpg\" for i in range(1000,1500)]\n",
        "\n",
        "for cname in cnames:\n",
        "    # code here\n",
        "    src = os.path.join(original_dataset_dir, cname)\n",
        "    dest = os.path.join(val_cats_dir, cname)\n",
        "    shutil.copyfile(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gRFQROVtAUct",
      "metadata": {
        "id": "gRFQROVtAUct"
      },
      "outputs": [],
      "source": [
        "# follow previous procedure as it is, just change only range(1000) --> range(1500, 2000)\n",
        "# also this time we are copying files to test_cats_dir, so change dest location to val_cats_dir.\n",
        "\n",
        "cnames = [f\"cat.{i}.jpg\" for i in range(1500,2000)]\n",
        "\n",
        "for cname in cnames:\n",
        "    # code here\n",
        "    src = os.path.join(original_dataset_dir, cname)\n",
        "    dest = os.path.join(test_cats_dir, cname)\n",
        "    shutil.copyfile(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UEviS94XAanQ",
      "metadata": {
        "id": "UEviS94XAanQ"
      },
      "outputs": [],
      "source": [
        "# making a list of image captions of dog using list comprehension(here we are copying first 1000 images of dog)\n",
        "\n",
        "dnames = [f\"dog.{i}.jpg\" for i in range(1000)]\n",
        "\n",
        "# loop over caption names in dnames and define a variable src by connecting original directory with the caption,\n",
        "# and then copy image from src to dest,  where dest variable is created by connecting train_dogs_dir with the caption.\n",
        "for dname in dnames:\n",
        "    # code here\n",
        "    src = os.path.join(original_dataset_dir, dname)\n",
        "    dest = os.path.join(train_dogs_dir, dname)\n",
        "    shutil.copyfile(src, dest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FisOy1SxAgtb",
      "metadata": {
        "id": "FisOy1SxAgtb"
      },
      "outputs": [],
      "source": [
        "# follow previous procedure as it is, just change only range(1000) --> range(1000, 1500)\n",
        "# also this time we are copying files to val_dogs_dir, so change dest location to val_dogs_dir.\n",
        "\n",
        "dnames = [f\"dog.{i}.jpg\" for i in range(1000,1500)]\n",
        "for dname in dnames:\n",
        "    # code here\n",
        "    src = os.path.join(original_dataset_dir, dname)\n",
        "    dest = os.path.join(val_dogs_dir, dname)\n",
        "    shutil.copyfile(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AN2n02bPAgwO",
      "metadata": {
        "id": "AN2n02bPAgwO"
      },
      "outputs": [],
      "source": [
        "# follow previous procedure as it is, just change only range(1000) --> range(1500, 2000)\n",
        "# also this time we are copying files to test_dogs_dir, so change dest location to test_dogs_dir.\n",
        "\n",
        "dnames = [f\"dog.{i}.jpg\" for i in range(1500,2000)]\n",
        "\n",
        "for dname in dnames:\n",
        "    # code here\n",
        "    src = os.path.join(original_dataset_dir, dname)\n",
        "    dest = os.path.join(test_dogs_dir, dname)\n",
        "    shutil.copyfile(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca40d43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ca40d43",
        "outputId": "23755444-6446-4a5b-a0c9-69e7e5f7e840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of cats in train: 1000\n",
            "The length of dogs in train: 1000\n",
            "The length of cats in validation:500 \n",
            "The length of dogs in validation: 500\n",
            "The length of cats in train: 500 \n",
            "The length of dogs in train:500 \n"
          ]
        }
      ],
      "source": [
        "# Now we will print length of cat and dog directories of train, validation and test directory from base_dir\n",
        "\n",
        "# code here\n",
        "print(\"The length of cats in train: {}\".format(len(os.listdir(train_cats_dir))))\n",
        "print(\"The length of dogs in train: {}\".format(len(os.listdir(train_dogs_dir))))\n",
        "# You can check same for test dir\n",
        "print(\"The length of cats in validation:{} \".format(len(os.listdir(val_cats_dir))))\n",
        "print(\"The length of dogs in validation: {}\".format(len(os.listdir(val_dogs_dir))))\n",
        "\n",
        "print(\"The length of cats in train: {} \".format(len(os.listdir(test_cats_dir))))\n",
        "print(\"The length of dogs in train:{} \".format(len(os.listdir(test_dogs_dir))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NpTbHTijNZde",
      "metadata": {
        "id": "NpTbHTijNZde"
      },
      "source": [
        "**If you have done data augmentation once, your output may be different than what's given above. **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b881d57c",
      "metadata": {
        "id": "b881d57c"
      },
      "outputs": [],
      "source": [
        "# Importing tensorflow and keras libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# defining the model and setup 3 convolutional layers, 3 maxpooling layers and then 2 dense layers in the end.\n",
        "# setup will be like this\n",
        "# conv2d-> maxpool2d, conv2d->maxpool2d, conv2d->maxpool2d, flatten layer, dense layer, dense layer\n",
        "\n",
        "model = models.Sequential()\n",
        "# add layers here\n",
        "model.add(layers.Conv2D(32,(3,3), activation=\"relu\",input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation=\"relu\"))\n",
        "model.add(layers.Dense(1,activation=\"sigmoid\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2e9c1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a2e9c1c",
        "outputId": "4727f4e5-1de2-417d-e1d9-19c9aff90b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18496)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               9470464   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9527297 (36.34 MB)\n",
            "Trainable params: 9527297 (36.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Print the summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abea5e24",
      "metadata": {
        "id": "abea5e24"
      },
      "outputs": [],
      "source": [
        "# Import optimizers and then compile your model, use loss='binary_crossentropy' and learning_rate=1e-4 with metrics=['acc']\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# compile your model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=['acc'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa74ae28",
      "metadata": {
        "id": "aa74ae28"
      },
      "outputs": [],
      "source": [
        "# Preprocessing step\n",
        "# importing Imagedatagenerator from tensorflow.keras.preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# rescale it to 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)# code here\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)# code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0889ce37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "0889ce37",
        "outputId": "75ae0924-5390-49c8-bddb-b66d923b1ef1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.preprocessing.image.ImageDataGenerator.flow_from_directory</b><br/>def flow_from_directory(directory, target_size=(256, 256), color_mode=&#x27;rgb&#x27;, classes=None, class_mode=&#x27;categorical&#x27;, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix=&#x27;&#x27;, save_format=&#x27;png&#x27;, follow_links=False, subset=None, interpolation=&#x27;nearest&#x27;, keep_aspect_ratio=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py</a>Takes the path to a directory &amp; generates batches of augmented data.\n",
              "\n",
              "Args:\n",
              "  directory: string, path to the target directory. It should contain\n",
              "    one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF images\n",
              "    inside each of the subdirectories directory tree will be included\n",
              "    in the generator. See [this script](\n",
              "    https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n",
              "    for more details.\n",
              "  target_size: Tuple of integers `(height, width)`. The dimensions to\n",
              "    which all images found will be resized. Defaults to `(256,256)`.\n",
              "  color_mode: One of &quot;grayscale&quot;, &quot;rgb&quot;, &quot;rgba&quot;. Default: &quot;rgb&quot;.\n",
              "    Whether the images will be converted to have 1, 3, or 4 channels.\n",
              "  classes: Optional list of class subdirectories (e.g. `[&#x27;dogs&#x27;,\n",
              "    &#x27;cats&#x27;]`). Default: None. If not provided, the list of classes\n",
              "    will be automatically inferred from the subdirectory\n",
              "    names/structure under `directory`, where each subdirectory will be\n",
              "    treated as a different class (and the order of the classes, which\n",
              "    will map to the label indices, will be alphanumeric). The\n",
              "    dictionary containing the mapping from class names to class\n",
              "    indices can be obtained via the attribute `class_indices`.\n",
              "  class_mode: One of &quot;categorical&quot;, &quot;binary&quot;, &quot;sparse&quot;,\n",
              "    &quot;input&quot;, or None.\n",
              "    Determines the type of label arrays that are returned:\n",
              "      - &quot;categorical&quot; will be 2D one-hot encoded labels,\n",
              "      - &quot;binary&quot; will be 1D binary labels,\n",
              "      - &quot;sparse&quot; will be 1D integer labels,\n",
              "      - &quot;input&quot; will be images identical\n",
              "        to input images (mainly used to work with autoencoders).\n",
              "      - If None, no labels are returned\n",
              "        (the generator will only yield batches of image data,\n",
              "        which is useful to use with `model.predict_generator()`).\n",
              "        Please note that in case of class_mode None,\n",
              "        the data still needs to reside in a subdirectory\n",
              "        of `directory` for it to work correctly.\n",
              "      Defaults to &quot;categorical&quot;.\n",
              "  batch_size: Size of the batches of data. Defaults to `32`.\n",
              "  shuffle: Whether to shuffle the data If `False`, sorts the\n",
              "    data in alphanumeric order. Defaults to `True`.\n",
              "  seed: Optional random seed for shuffling and transformations.\n",
              "  save_to_dir: None or str (default: None). This allows you to\n",
              "    optionally specify a directory to which to save the augmented\n",
              "    pictures being generated (useful for visualizing what you are\n",
              "    doing).\n",
              "  save_prefix: Str. Prefix to use for filenames of saved pictures\n",
              "    (only relevant if `save_to_dir` is set).\n",
              "  save_format: one of &quot;png&quot;, &quot;jpeg&quot;, &quot;bmp&quot;, &quot;pdf&quot;, &quot;ppm&quot;, &quot;gif&quot;,\n",
              "    &quot;tif&quot;, &quot;jpg&quot; (only relevant if `save_to_dir` is set).\n",
              "    Defaults to &quot;png&quot;.\n",
              "  follow_links: Whether to follow symlinks inside\n",
              "    class subdirectories. Defaults to `False`.\n",
              "  subset: Subset of data (`&quot;training&quot;` or `&quot;validation&quot;`) if\n",
              "    `validation_split` is set in `ImageDataGenerator`.\n",
              "  interpolation: Interpolation method used to resample the image if\n",
              "    the target size is different from that of the loaded image.\n",
              "    Supported methods are `&quot;nearest&quot;`, `&quot;bilinear&quot;`, and `&quot;bicubic&quot;`.\n",
              "    If PIL version 1.1.3 or newer is installed, `&quot;lanczos&quot;` is also\n",
              "    supported. If PIL version 3.4.0 or newer is installed, `&quot;box&quot;` and\n",
              "    `&quot;hamming&quot;` are also supported. Defaults to `&quot;nearest&quot;`.\n",
              "  keep_aspect_ratio: Boolean, whether to resize images to a target\n",
              "    size without aspect ratio distortion. The image is cropped in\n",
              "    the center with target aspect ratio before resizing.\n",
              "\n",
              "Returns:\n",
              "  A `DirectoryIterator` yielding tuples of `(x, y)`\n",
              "    where `x` is a numpy array containing a batch\n",
              "    of images with shape `(batch_size, *target_size, channels)`\n",
              "    and `y` is a numpy array of corresponding labels.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1562);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<bound method ImageDataGenerator.flow_from_directory of <keras.src.preprocessing.image.ImageDataGenerator object at 0x7a046c2d1750>>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# uncomment it to see what it explain about the method\n",
        "train_datagen.flow_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8862a09a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8862a09a",
        "outputId": "d687d7d4-5f3f-4d2b-b471-238520675033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# create generators of train and validation using train_datagen.flow_from_directory\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\")# code here\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode=\"binary\") # code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41292b12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41292b12",
        "outputId": "c47498eb-f707-47ca-8a00-397f178b115c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data batch size:(20, 150, 150, 3)\n",
            "label soze:(20,)\n"
          ]
        }
      ],
      "source": [
        "# let's loop over train generator to see what does it show\n",
        "for data_batch, label in train_generator:\n",
        "    # code here\n",
        "    print(\"Data batch size:{}\".format(data_batch.shape))\n",
        "    print(\"label soze:{}\".format(label.shape))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67397cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "e67397cc",
        "outputId": "40c84679-51b5-4b27-9500-d44fceddab4e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fa2e84cfe393>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fitting the model by passing train_generator as first arguement with necessary parameters like steps_per_epoch=100, for 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# also pass validation data and validation steps=50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# fitting the model by passing train_generator as first arguement with necessary parameters like steps_per_epoch=100, for 10 epochs\n",
        "# also pass validation data and validation steps=50\n",
        "history = model.fit(train_generator,steps_per_epoch=100 ,epochs=10 , validation_data=validation_generator , validation_steps=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a05b5a0",
      "metadata": {
        "id": "2a05b5a0"
      },
      "outputs": [],
      "source": [
        "# save the model for futher use using model.save\n",
        "# code here\n",
        "model.save('cat_dog_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb01dd6",
      "metadata": {
        "id": "2eb01dd6"
      },
      "outputs": [],
      "source": [
        "# print the accuracy using history.history['acc']\n",
        "acc = history.history['acc']\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48366b51",
      "metadata": {
        "id": "48366b51"
      },
      "outputs": [],
      "source": [
        "# print validation accuracy using same as previous step\n",
        "val_acc = history.history['val_acc']# code here\n",
        "val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58910f6",
      "metadata": {
        "id": "e58910f6"
      },
      "outputs": [],
      "source": [
        "# print loss using same as previous steps\n",
        "loss =  history.history['loss']# code here\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a55082",
      "metadata": {
        "id": "c4a55082"
      },
      "outputs": [],
      "source": [
        "# print val_loss using same as previous steps\n",
        "\n",
        "val_loss =  history.history['val_loss'] # code here\n",
        "val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VZr5H7Kl0Ssw",
      "metadata": {
        "id": "VZr5H7Kl0Ssw"
      },
      "source": [
        "**Plotting accuracies and loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b1722c",
      "metadata": {
        "id": "83b1722c"
      },
      "outputs": [],
      "source": [
        "# import pyplot from matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# define no of epochs and then plot epoch vs accuracies of train and validation\n",
        "epochs = range(1, len(acc)+1)\n",
        "# code here\n",
        "plt.plot(epochs,acc,'o',label='training_acc')\n",
        "plt.plot(epochs,val_acc,'b',label='val_acc')\n",
        "plt.title(\"training and val accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb4da3ad",
      "metadata": {
        "id": "eb4da3ad"
      },
      "outputs": [],
      "source": [
        "# # define no of epochs and then plot epoch vs loss of train and validation\n",
        "\n",
        "# code here\n",
        "plt.plot(epochs,loss,'bo',label='training_loss')\n",
        "plt.plot(epochs,val_loss,'b',label='val_loss')\n",
        "plt.title(\"training and val loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e9325a",
      "metadata": {
        "id": "27e9325a"
      },
      "outputs": [],
      "source": [
        "# setting up data augmentation config using ImageDataGenerator using these parameters\n",
        "# rotation_range=40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2,\n",
        "# zoom_range = 0.2, horizontal_flip = True, fill_mode = 'nearest'\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator( rotation_range=40, width_shift_range = 0.2,\n",
        "                             height_shift_range = 0.2, shear_range = 0.2,\n",
        "                              zoom_range = 0.2, horizontal_flip = True,\n",
        "                              fill_mode = 'nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c559c2",
      "metadata": {
        "id": "e1c559c2"
      },
      "outputs": [],
      "source": [
        "# displaying some augmented images using image from keras.preprocessing\n",
        "from keras.preprocessing import image\n",
        "\n",
        "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
        "img_path = fnames[3]\n",
        "\n",
        "# now use load_img method of image to load the picture keeping target size (150,150)\n",
        "\n",
        "img = image.load_img(img_path,target_size=(150,150))\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba26b1c",
      "metadata": {
        "id": "2ba26b1c"
      },
      "outputs": [],
      "source": [
        "# converting image into array\n",
        "x = image.img_to_array(img) # --> gives (150,150,3) array\n",
        "x = x.reshape((1,) + x.shape) # reshapes to (1,150,150,3) array\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i%4 == 0:\n",
        "        break\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b204e57",
      "metadata": {
        "id": "3b204e57"
      },
      "outputs": [],
      "source": [
        "# new model creation like we did before(You can change no of neurons according to your intution for experiment)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3), activation=\"relu\",input_shape=(150,150,3)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3), activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(512, activation=\"relu\"))\n",
        "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = optimizers.RMSprop(learning_rate=1e-4),\n",
        "             metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce973333",
      "metadata": {
        "id": "ce973333"
      },
      "outputs": [],
      "source": [
        "# training with augmented data, use ImageDataGenerator and pass rescale=1./255 and keep rest parameters same like we did before\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, rotation_range=40, width_shift_range = 0.2,\n",
        "                             height_shift_range = 0.2, shear_range = 0.2,\n",
        "                              zoom_range = 0.2, horizontal_flip = True,\n",
        "                              fill_mode = 'nearest')\n",
        "\n",
        "\n",
        "\n",
        "# define test_datagen for validation\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c75b01",
      "metadata": {
        "id": "14c75b01"
      },
      "outputs": [],
      "source": [
        "# defining train_generator and validation_generator again\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                   target_size = (150, 150),\n",
        "                                   batch_size = 32,\n",
        "                                   class_mode = 'binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa8718d0",
      "metadata": {
        "id": "aa8718d0"
      },
      "outputs": [],
      "source": [
        "# fitting the model, you can change epoch from 5 to 10 or 20 for experimentation purposes\n",
        "\n",
        "\n",
        "history = model.fit(train_generator ,epochs=5 , validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9-x7qZsnMwgO",
      "metadata": {
        "id": "9-x7qZsnMwgO"
      },
      "outputs": [],
      "source": [
        "# You can save model again for reuse\n",
        "model.save('cats_and_dogs_small_model2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed9ef0f9",
      "metadata": {
        "id": "ed9ef0f9"
      },
      "outputs": [],
      "source": [
        "# define acc, train_loss, val_acc, val_loss again from history.history method\n",
        "acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss =history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37efb94b",
      "metadata": {
        "id": "37efb94b"
      },
      "outputs": [],
      "source": [
        "# define epochs again and plot epochs vs accuracy for both train and validation\n",
        "epochs = range(1, len(acc)+1)\n",
        "plt.plot(epochs,acc,'o',label='training_acc')\n",
        "plt.plot(epochs,val_acc,'b',label='val_acc')\n",
        "plt.title(\"training and val accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6016a848",
      "metadata": {
        "id": "6016a848"
      },
      "outputs": [],
      "source": [
        "# define epochs again and plot epochs vs loss for both train and validation\n",
        "\n",
        "plt.plot(epochs, loss,'bo',label='training_loss')\n",
        "plt.plot(epochs,val_loss,'b',label='val_loss')\n",
        "plt.title(\"training and val loss\")\n",
        "plt.legend()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MrxwURTa-Oze",
      "metadata": {
        "id": "MrxwURTa-Oze"
      },
      "source": [
        "**Feature extraction using pretrained VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c59f30",
      "metadata": {
        "id": "f9c59f30"
      },
      "outputs": [],
      "source": [
        "# Using pretrained network ImageNet (Method = Feature extraction)\n",
        "#import VGG16 from tensorflow\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "# instantantiating VGG16 and pass include_top = False, weights='imagenet' and input shape = (150,150,3)\n",
        "\n",
        "conv_base = VGG16(weights='imagenet', include_top = False, input_shape = (150,150,3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6lcQ1vSeOL2S",
      "metadata": {
        "id": "6lcQ1vSeOL2S"
      },
      "outputs": [],
      "source": [
        "# printing summary\n",
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77C3QsXZOVgc",
      "metadata": {
        "id": "77C3QsXZOVgc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# location of main directories(base_dir, train_dir, validation_dir, test_dir )\n",
        "base_dir = \"/content/drive/MyDrive/cat_dog_small/cat_dog\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "\n",
        "# image datagen and batch size\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 25\n",
        "\n",
        "# Read code line by line and try to understand what it does\n",
        "# defining feature_extraction function (feature extraction without data augmentation)\n",
        "def feature_extraction(directory, sample):\n",
        "  features = np.zeros(shape=(sample, 4, 4, 512))\n",
        "  labels = np.zeros(shape=(sample))\n",
        "  generator = datagen.flow_from_directory(\n",
        "      directory,\n",
        "      target_size=(150, 150),\n",
        "      batch_size = batch_size,\n",
        "      class_mode = 'binary'\n",
        "  )\n",
        "  count = 0\n",
        "  for image_batch, labels_batch in generator:\n",
        "    batch_feature = conv_base.predict(image_batch)\n",
        "    features[count * batch_size : (count+1) * batch_size] = batch_feature\n",
        "    labels[count * batch_size : (count+1) * batch_size] = labels_batch\n",
        "    count += 1\n",
        "    if count * batch_size >= sample:\n",
        "      break\n",
        "  return features, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "doYgrXueTrIE",
      "metadata": {
        "id": "doYgrXueTrIE"
      },
      "outputs": [],
      "source": [
        "# Now extract features for train, validation, test\n",
        "\n",
        "train_features, train_labels = feature_extraction(train_dir,2000)\n",
        "validation_features, validation_labels = feature_extraction(validation_dir,1000)\n",
        "test_features, test_labels = feature_extraction(test_dir,1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eD5PzWQaVlNg",
      "metadata": {
        "id": "eD5PzWQaVlNg"
      },
      "outputs": [],
      "source": [
        "# reshape, train, validation, test into (no of samples, 4*4*512) features before passing into dense layers\n",
        "train_features = np.reshape(train_features,(2000,4*4*512))\n",
        "validation_features = np.reshape(validation_features,(1000,4*4*512))\n",
        "test_features = np.reshape(test_features,(1000,4*4*512))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EFtxfQ5VV5sk",
      "metadata": {
        "id": "EFtxfQ5VV5sk"
      },
      "outputs": [],
      "source": [
        "# define a new model and  add dense classfier first then dropout(0.5) and then final dense layer with activation sigmoid\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(128, activation=\"relu\",input_dim=4*4*512))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer = optimizers.RMSprop(learning_rate=1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ch61GgfEWr0K",
      "metadata": {
        "id": "ch61GgfEWr0K"
      },
      "outputs": [],
      "source": [
        "# fit the model with epochs = 10 and batch_size=20\n",
        "vgg_history = model.fit(train_features ,train_labels,epochs=10 ,batch_size=20, validation_data=(validation_generator,validation_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JBndsCg3Xb30",
      "metadata": {
        "id": "JBndsCg3Xb30"
      },
      "outputs": [],
      "source": [
        "# define acc, loss, val_acc, val_loss again from history.history method\n",
        "\n",
        "acc = vgg_history.history['acc']\n",
        "loss = vgg_history.history['loss']\n",
        "val_acc = vgg_history.history['val_acc']\n",
        "val_loss =vgg_history.history['val_loss']\n",
        "\n",
        "# then plot epochs vs train accuracy and validation accuracy\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs,acc,'bo',label='training_acc')\n",
        "plt.plot(epochs,val_acc,'b',label='val_acc')\n",
        "plt.title(\"training and val accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xA-IKQcHXeYI",
      "metadata": {
        "id": "xA-IKQcHXeYI"
      },
      "outputs": [],
      "source": [
        "# plot epochs vs train loss and validation loss\n",
        "plt.plot(epochs,loss,'bo',label='training_loss')\n",
        "plt.plot(epochs,val_loss,'b',label='val_loss')\n",
        "plt.title(\"training and val accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fvu2Mhnp-Z3J",
      "metadata": {
        "id": "fvu2Mhnp-Z3J"
      },
      "outputs": [],
      "source": [
        "# You can evaluate your final model on test dataset if you want.....\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "test_dir,\n",
        "target_size=(150, 150),\n",
        "batch_size=20,\n",
        "class_mode='binary')\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "print('test acc:', test_acc)\n",
        "\n",
        "# Also play with changing the no of layers and neurons of the layers to see how accuracy changes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Af-cBp4FUGr",
      "metadata": {
        "id": "2Af-cBp4FUGr"
      },
      "source": [
        "![finish](https://static8.depositphotos.com/1472772/978/i/950/depositphotos_9787455-stock-photo-finish-flags.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pWLjQtN7w2FL",
      "metadata": {
        "id": "pWLjQtN7w2FL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}